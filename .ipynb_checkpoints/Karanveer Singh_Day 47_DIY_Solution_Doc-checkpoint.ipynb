{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bac6311-4d7a-4a51-b172-ac408d86afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\palvi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens after lowercasing:\n",
      "\n",
      "['he', 'can', 'even', 'spout', 'some', 'sports', 'trivia', 'and', 'christmas', 'carols', 'and', 'stuff', 'like', 'that', '.']\n",
      "['we', \"'d\", 'talk', 'sports', 'and', 'stuff', ',', 'and', 'maybe', 'have', 'a', 'beer', '.']\n",
      "['the', 'admirable', 'crichton', 'of', 'his', 'day', ',', 'he', 'was', 'keen', 'alike', 'on', 'field', 'sports', 'and', 'the', 'arts', ',', 'the', 'friend', 'and', 'admirer', 'equally', 'of', 'cecil', 'rhodes', 'and', 'of', 'rodin', ',', 'a', 'railway', 'director', 'and', 'a', 'yeomanry', 'colonel', '.']\n",
      "['but', 'he', 'was', 'not', 'brought', 'forward', 'by', 'his', 'father', 'or', 'prepared', 'in', 'any', 'way', 'for', 'his', 'future', 'greatness', ',', 'and', 'lived', 'in', 'the', 'country', 'occupied', 'with', 'field', 'sports', ',', 'till', 'after', 'the', 'institution', 'of', 'the', 'second', 'protectorate', 'in', '16j7', 'and', 'the', 'recognition', 'of', 'oliver', \"'s\", 'right', 'to', 'name', 'his', 'successor', '.']\n",
      "['thankfully', ',', 'he', 'was', 'too', 'concerned', 'with', 'sports', 'to', 'get', 'in', 'any', 'real', 'trouble', '.']\n",
      "['see', 'strutt', ',', 'sports', 'and', 'pastimes', ',', 'who', 'also', 'gives', 'an', 'illustration', ',', '``', 'taken', 'from', 'a', 'manuscriptal', 'painting', 'of', 'the', '9th', 'century', 'in', 'the', 'cotton', 'library', ',', \"''\", 'representing', '``', 'a', 'saxon', 'chieftain', ',', 'attended', 'by', 'his', 'huntsman', 'and', 'a', 'couple', 'of', 'hounds', ',', 'pursuing', 'the', 'wild', 'swine', 'in', 'a', 'forest', '.', \"''\"]\n",
      "['as', 'they', 'entered', 'the', 'yard', ',', 'carmen', 'noticed', 'lori', \"'s\", 'little', 'red', 'sports', 'car', '.']\n",
      "['after', 'a', 'lengthy', 'shower', ',', 'jenn', 'exited', 'and', 'pulled', 'on', 'clean', 'leggings', ',', 'sports', 'bra', ',', 'and', 'socks', '.']\n",
      "['a', 'park', 'and', 'sports', 'ground', 'at', 'the', 'western', 'end', 'of', 'the', 'town', 'contains', 'the', 'pedestal', 'for', 'a', 'statue', 'of', 'president', 'kruger', '.']\n",
      "['there', 'were', 'crude', 'medieval', 'notions', 'that', 'fossils', 'were', '``', 'freaks', '``', 'or', '``', 'sports', '``', 'of', 'nature', '(', 'lusus', 'naturae', ')', ',', 'or', 'that', 'they', 'represented', 'failures', 'of', 'a', 'creative', 'force', 'within', 'the', 'earth', '(', 'a', 'notion', 'of', 'greek', 'and', 'arabic', 'origin', ')', ',', 'or', 'that', 'larger', 'and', 'smaller', 'fossils', 'represented', 'the', 'remains', 'of', 'races', 'of', 'giants', 'or', 'of', 'pygmies', '(', 'the', 'mythical', 'idea', ')', '.']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.18882823 ... 0.         0.         0.18882823]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.11784944 0.         0.        ]]\n",
      "\n",
      "Feature Names (terms):\n",
      "\n",
      "['16j7' '9th' 'admirable' 'admirer' 'after' 'alike' 'also' 'an' 'and'\n",
      " 'any' 'arabic' 'arts' 'as' 'at' 'attended' 'beer' 'bra' 'brought' 'but'\n",
      " 'by' 'can' 'car' 'carmen' 'carols' 'cecil' 'century' 'chieftain'\n",
      " 'christmas' 'clean' 'colonel' 'concerned' 'contains' 'cotton' 'country'\n",
      " 'couple' 'creative' 'crichton' 'crude' 'day' 'director' 'earth' 'end'\n",
      " 'entered' 'equally' 'even' 'exited' 'failures' 'father' 'field' 'for'\n",
      " 'force' 'forest' 'forward' 'fossils' 'freaks' 'friend' 'from' 'future'\n",
      " 'get' 'giants' 'gives' 'greatness' 'greek' 'ground' 'have' 'he' 'his'\n",
      " 'hounds' 'huntsman' 'idea' 'illustration' 'in' 'institution' 'jenn'\n",
      " 'keen' 'kruger' 'larger' 'leggings' 'lengthy' 'library' 'like' 'little'\n",
      " 'lived' 'lori' 'lusus' 'manuscriptal' 'maybe' 'medieval' 'mythical'\n",
      " 'name' 'naturae' 'nature' 'not' 'noticed' 'notion' 'notions' 'occupied'\n",
      " 'of' 'oliver' 'on' 'or' 'origin' 'painting' 'park' 'pastimes' 'pedestal'\n",
      " 'prepared' 'president' 'protectorate' 'pulled' 'pursuing' 'pygmies'\n",
      " 'races' 'railway' 'real' 'recognition' 'red' 'remains' 'represented'\n",
      " 'representing' 'rhodes' 'right' 'rodin' 'saxon' 'second' 'see' 'shower'\n",
      " 'smaller' 'socks' 'some' 'sports' 'spout' 'statue' 'strutt' 'stuff'\n",
      " 'successor' 'swine' 'taken' 'talk' 'thankfully' 'that' 'the' 'there'\n",
      " 'they' 'till' 'to' 'too' 'town' 'trivia' 'trouble' 'was' 'way' 'we'\n",
      " 'were' 'western' 'who' 'wild' 'with' 'within' 'yard' 'yeomanry']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "\n",
    "file_path = 'demotext2.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "tokens_per_sentence = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "tokens_per_sentence_lower = [\n",
    "    [token.lower() for token in sentence] for sentence in tokens_per_sentence\n",
    "]\n",
    "\n",
    "print(\"Tokens after lowercasing:\\n\")\n",
    "for sentence_tokens in tokens_per_sentence_lower:\n",
    "    print(sentence_tokens)\n",
    "\n",
    "sentences_processed = [' '.join(sentence) for sentence in tokens_per_sentence_lower]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences_processed)\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\\n\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "print(\"\\nFeature Names (terms):\\n\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a930c2-97ce-4741-89f5-20db8b9951d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
