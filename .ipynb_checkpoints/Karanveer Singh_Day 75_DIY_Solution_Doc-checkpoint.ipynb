{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b70eb2f6-58dc-4511-9be3-42f1dc712d38",
   "metadata": {},
   "source": [
    "Q1. What is a Perceptron?\n",
    "A perceptron is the simplest type of artificial neural network, which serves as a building block for more complex neural networks. It was introduced by Frank Rosenblatt in 1958.\n",
    "\n",
    "A perceptron consists of:\n",
    "\n",
    "Input features: A vector of numerical values.\n",
    "Weights: Values that represent the importance of each input.\n",
    "Bias: A term added to adjust the output, independent of the input.\n",
    "Activation function: A function to determine the output based on a threshold."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff8aadbf-95de-4c3c-a6db-fc739d863a17",
   "metadata": {},
   "source": [
    "Q2. How does a Perceptron work?\n",
    "The perceptron works by following these steps:\n",
    "\n",
    "Weighted Sum Calculation: Compute the weighted sum of inputs:\n",
    "\n",
    "ğ‘§\n",
    "=\n",
    "âˆ‘\n",
    "(\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "â‹…\n",
    "ğ‘¥\n",
    "ğ‘–\n",
    ")\n",
    "+\n",
    "ğ‘\n",
    "z=âˆ‘(w \n",
    "i\n",
    "â€‹\n",
    " â‹…x \n",
    "i\n",
    "â€‹\n",
    " )+b\n",
    "where \n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "w \n",
    "i\n",
    "â€‹\n",
    "  are weights, \n",
    "ğ‘¥\n",
    "ğ‘–\n",
    "x \n",
    "i\n",
    "â€‹\n",
    "  are inputs, and \n",
    "ğ‘\n",
    "b is the bias.\n",
    "\n",
    "Apply Activation Function: Pass the weighted sum \n",
    "ğ‘§\n",
    "z through an activation function (often a step function for perceptrons). For binary classification:\n",
    "\n",
    "Output\n",
    "=\n",
    "{\n",
    "1\n",
    "ifÂ \n",
    "ğ‘§\n",
    "â‰¥\n",
    "0\n",
    "0\n",
    "ifÂ \n",
    "ğ‘§\n",
    "<\n",
    "0\n",
    "Output={ \n",
    "1\n",
    "0\n",
    "â€‹\n",
    "  \n",
    "ifÂ zâ‰¥0\n",
    "ifÂ z<0\n",
    "â€‹\n",
    " \n",
    "Update Weights (During Training): Adjust weights based on errors using a learning rule.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c79e6521-cc8b-4008-840f-1d086704febf",
   "metadata": {},
   "source": [
    "Q3. What is the Perceptron Algorithm?\n",
    "The perceptron algorithm is a supervised learning algorithm for training binary classifiers. It works iteratively to minimize classification errors. Steps include:\n",
    "\n",
    "Initialize weights and bias to small random values.\n",
    "For each training example:\n",
    "Compute the predicted output using the perceptron formula.\n",
    "Update the weights and bias if the prediction is incorrect:\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "â†\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "+\n",
    "ğœ‚\n",
    "â‹…\n",
    "(\n",
    "ğ‘¦\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "^\n",
    ")\n",
    "â‹…\n",
    "ğ‘¥\n",
    "ğ‘–\n",
    "w \n",
    "i\n",
    "â€‹\n",
    " â†w \n",
    "i\n",
    "â€‹\n",
    " +Î·â‹…(yâˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    " )â‹…x \n",
    "i\n",
    "â€‹\n",
    " \n",
    "ğ‘\n",
    "â†\n",
    "ğ‘\n",
    "+\n",
    "ğœ‚\n",
    "â‹…\n",
    "(\n",
    "ğ‘¦\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "^\n",
    ")\n",
    "bâ†b+Î·â‹…(yâˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    " )\n",
    "where:\n",
    "ğœ‚\n",
    "Î·: learning rate\n",
    "ğ‘¦\n",
    "y: actual label\n",
    "ğ‘¦\n",
    "^\n",
    "y\n",
    "^\n",
    "â€‹\n",
    " : predicted label\n",
    "Repeat until the model converges or for a fixed number of iterations."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0842558-3f0e-439c-b96e-64ce5ef8adf8",
   "metadata": {},
   "source": [
    "Q5. What is Forward Propagation?\n",
    "Forward propagation is the process by which inputs are passed through a neural network to generate predictions. It involves:\n",
    "\n",
    "Input Layer: Inputs \n",
    "ğ‘¥\n",
    "x are fed to the network.\n",
    "Hidden Layers: Each layer computes:\n",
    "ğ‘§=âˆ‘(ğ‘¤â‹…ğ‘¥)+ğ‘\n",
    "z=âˆ‘(wâ‹…x)+b\n",
    "and applies an activation function.\n",
    "Output Layer: The final layer outputs predictions.\n",
    "Forward propagation ends with the computation of the loss function, which quantifies the difference between the predictions and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc161f8-d32f-4ce7-aa41-238c160c29cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
